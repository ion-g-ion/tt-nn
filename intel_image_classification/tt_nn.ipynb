{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tn\n",
    "from torchvision import datasets, transforms\n",
    "import torchtt as tntt\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = 'cuda:0'\n",
    "data_dir_test = 'seg_test/'\n",
    "data_dir_train = 'seg_train/'\n",
    "N_shape = [15,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.Resize(N_shape[0]*N_shape[1]), transforms.CenterCrop(N_shape[0]*N_shape[1]), transforms.ToTensor()]) #, transforms.Normalize(tn.tensor([0.4885, 0.4525, 0.4163]), tn.tensor([0.2549, 0.2476, 0.2495]))])\n",
    "dataset_train = datasets.ImageFolder(data_dir_train, transform=transform_train)\n",
    "dataloader_train = tn.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(N_shape[0]*N_shape[1]), transforms.CenterCrop(N_shape[0]*N_shape[1]), transforms.ToTensor()]) #, transforms.Normalize(tn.tensor([0.4885, 0.4525, 0.4163]), tn.tensor([0.2549, 0.2476, 0.2495])) ])\n",
    "dataset_test = datasets.ImageFolder(data_dir_test, transform=transform_test)\n",
    "dataloader_test = tn.utils.data.DataLoader(dataset_test, batch_size=32, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "\n",
    "# inputs_train = list(dataloader_train)[0][0].to(device_name)\n",
    "# labels_train = list(dataloader_train)[0][1].to(device_name)\n",
    "# \n",
    "# inputs_test = list(dataloader_test)[0][0].to(device_name)\n",
    "# labels_test = list(dataloader_test)[0][1].to(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        p = 0.5\n",
    "        self.ttl1 = tntt.nn.LinearLayerTT([3]+N_shape+N_shape, [16]+N_shape+N_shape, [1,9,3,3,2,1], initializer = 'He')\n",
    "        self.dropout1 = nn.Dropout(p)\n",
    "        self.ttl2 = tntt.nn.LinearLayerTT([16]+N_shape+N_shape, [32,8,8,8,8], [1,8,4,3,2,1], initializer = 'He')\n",
    "        self.dropout2 = nn.Dropout(p)\n",
    "        self.ttl3 = tntt.nn.LinearLayerTT([32,8,8,8,8], [8,4,4,4,4], [1,4,4,4,4,1], initializer = 'He')\n",
    "        self.dropout3 = nn.Dropout(p)\n",
    "        self.ttl4 = tntt.nn.LinearLayerTT([8,4,4,4,4], [4,4,4,4,4], [1,2,2,2,2,1], initializer = 'He')\n",
    "        self.dropout4 = nn.Dropout(p)\n",
    "        self.ttl5 = tntt.nn.LinearLayerTT([4,4,4,4,4], [4,4,4,4,4], [1,2,2,2,2,1], initializer = 'He')\n",
    "        self.dropout5 = nn.Dropout(p)\n",
    "        self.ttl6 = tntt.nn.LinearLayerTT([4,4,4,4,4], [3,3,3,3,3], [1,3,3,3,3,1], initializer = 'He')\n",
    "        self.dropout6 = nn.Dropout(p)\n",
    "        self.linear = nn.Linear(3**5, 6, dtype = tn.float32)\n",
    "        self.logsoftmax = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ttl1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = tn.relu(x)\n",
    "        x = self.ttl2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = tn.relu(x)\n",
    "        x = self.ttl3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = tn.relu(x)\n",
    "        x = self.ttl4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = tn.relu(x)\n",
    "        x = self.ttl5(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = tn.relu(x)\n",
    "        x = self.ttl6(x)\n",
    "        x = self.dropout6(x)\n",
    "        x = tn.relu(x)\n",
    "        x = x.view(-1,3**5)\n",
    "        x = self.linear(x)\n",
    "        return self.logsoftmax(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicTT()        \n",
    "model.to(device_name)\n",
    "\n",
    "print('Number of parameters', sum(tn.numel(p) for p in model.parameters()))\n",
    "\n",
    "optimizer = tn.optim.SGD(model.parameters(), lr=0.001, momentum=0.1)\n",
    "# optimizer = tn.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = tn.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "\n",
    "loss_function = tn.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(i):\n",
    "    \n",
    "    loss_total = 0.0\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "    #tme = datetime.datetime.now()\n",
    "    for k, data in enumerate(dataloader_train):\n",
    "        #tme = datetime.datetime.now() - tme\n",
    "        #print('t0',tme)\n",
    "        #tme = datetime.datetime.now()\n",
    "        inputs, labels = data[0].to(device_name), data[1].to(device_name)\n",
    "        #tme = datetime.datetime.now() - tme\n",
    "        #print('t1',tme)\n",
    "        \n",
    "        #tme = datetime.datetime.now()\n",
    "        inputs = tn.reshape(inputs,[-1,3]+2*N_shape)\n",
    "        #tme = datetime.datetime.now() - tme\n",
    "        #print('t2',tme)\n",
    "        \n",
    "        #tme = datetime.datetime.now()\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # regularization\n",
    "        #l2_lambda = 0.005\n",
    "        #l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        loss = loss#+l2_lambda*l2_norm\n",
    "        \n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        #tme = datetime.datetime.now() - tme\n",
    "        #print('t3',tme)\n",
    "        n_correct += tn.sum(tn.max(outputs,1)[1] == labels).cpu()   \n",
    "        n_total+=inputs.shape[0]\n",
    "        \n",
    "        loss_total += loss.item()\n",
    "        # print('\\t\\tbatch %d error %e'%(k+1,loss))\n",
    "        #tme = datetime.datetime.now()\n",
    "        \n",
    "    return loss_total/len(dataloader_train), n_correct/n_total\n",
    "\n",
    "def test_loss():\n",
    "    loss_total = 0 \n",
    "    for data in dataloader_test:\n",
    "        inputs, labels = data[0].to(device_name), data[1].to(device_name)\n",
    "        inputs = tn.reshape(inputs,[-1,3]+2*N_shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "    return loss_total/len(dataloader_test)\n",
    "\n",
    "def test_data():\n",
    "    n_total = 0 \n",
    "    n_correct = 0\n",
    "    loss_total = 0\n",
    "    \n",
    "    for data in dataloader_test:\n",
    "        inputs, labels = data[0].to(device_name), data[1].to(device_name)\n",
    "        inputs = tn.reshape(inputs,[-1,3]+2*N_shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss_total += loss.item()\n",
    "        n_correct += tn.sum(tn.max(outputs,1)[1] == labels)   \n",
    "        n_total+=inputs.shape[0]\n",
    "        \n",
    "    return loss_total/len(dataloader_test), n_correct/n_total\n",
    "\n",
    "def train_accuracy():\n",
    "    n_total = 0 \n",
    "    n_correct = 0\n",
    "    \n",
    "    for data in dataloader_train:\n",
    "        inputs, labels = data[0].to(device_name), data[1].to(device_name)\n",
    "        inputs = tn.reshape(inputs,[-1,3]+2*N_shape)\n",
    "        outputs = model(inputs)\n",
    "        n_correct += tn.sum(tn.max(outputs,1)[1] == labels)   \n",
    "        n_total+=inputs.shape[0]\n",
    "        \n",
    "    return n_correct/n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 150\n",
    "\n",
    "history_test_accuracy = []\n",
    "history_test_loss = []\n",
    "history_train_accuracy = []\n",
    "history_train_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch %d/%d'%(epoch+1,n_epochs))\n",
    "    \n",
    "    time_epoch = datetime.datetime.now()\n",
    "    \n",
    "    model.train(True)\n",
    "    train_loss, train_acc = do_epoch(epoch)\n",
    "    model.train(False)\n",
    "    \n",
    "    test_loss, test_acc = test_data()\n",
    "    scheduler.step()\n",
    "    \n",
    "    time_epoch = datetime.datetime.now() - time_epoch\n",
    "    \n",
    "    print('\\tTraining loss %e training accuracy %5.4f test loss %e test accuracy %5.4f'%(train_loss,train_acc,test_loss,test_acc))\n",
    "    print('\\tTime for the epoch',time_epoch)\n",
    "    history_test_accuracy.append(test_acc)\n",
    "    history_test_loss.append(test_loss)\n",
    "    history_train_accuracy.append(train_acc)\n",
    "    history_train_loss.append(train_loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(history_train_accuracy))+1,np.array(history_train_accuracy))\n",
    "plt.plot(np.arange(len(history_test_accuracy))+1,np.array(history_test_accuracy))\n",
    "plt.legend(['training','test'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(history_train_loss))+1,np.array(history_train_loss))\n",
    "plt.plot(np.arange(len(history_test_loss))+1,np.array(history_test_loss))\n",
    "plt.legend(['training','test'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(history_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bb18d59442045223691660a1f8e0079e69ab2417ab62beafa5ba9155c0a563f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
